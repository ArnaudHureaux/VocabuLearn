{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304dd57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6ca50",
   "metadata": {},
   "source": [
    "STEP 1\n",
    "\n",
    "- get frequency of words\n",
    "- fusion wit the databses containing the translations\n",
    "\n",
    "STEP 2\n",
    "\n",
    "- front \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6fe26",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Extracting & cleaning occurence / words with filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc32521",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**cleaning rapide avec scipy/nltk?**\n",
    "\n",
    "- Filter with the words of the english language : http://www.mieliestronk.com/wordlist.html\n",
    "- stopword, numbers, names, special charaters, remove foreign words\n",
    "- split les mots en deux avec un ' au milieu\n",
    "\n",
    "**Fusion with the dataset containing french & english words**\n",
    "\n",
    "- how to avoid a infinite runtime ?? \n",
    "- tokenization : https://machinelearningmastery.com/clean-text-machine-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f2d8743",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# StopWords\n",
    "# nltk.download()\n",
    "stop_words = stopwords.words('english')\n",
    "# print(stop_words)\n",
    "\n",
    "\n",
    "# Special characters\n",
    "List_special = []\n",
    "for caracter in '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\"' :\n",
    "    List_special.append(caracter)\n",
    "    \n",
    "    \n",
    "# List of english words\n",
    "with open(\"english_language_lowercase.txt\", 'r', encoding='UTF-8') as file:\n",
    "    lines_english_language1 = file.readlines()\n",
    "    lines_english_language = [line.rstrip() for line in lines_english_language1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8df1c329",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2184780/2184780 [35:53<00:00, 1014.47it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-436fa13e8a85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mliste_occurences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m df = pd.DataFrame({\"words\" : liste_words,\n\u001b[0m\u001b[0;32m     13\u001b[0m                  \"occurences\" : liste_occurences})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "filename = \"enwiki-20190320-words-frequency.txt\"\n",
    "\n",
    "with open(filename, 'r', encoding='UTF-8') as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in tqdm(lines) if line.split(\" \")[0] in lines_english_language]\n",
    "\n",
    "# new_list = [line.split(\" \") for line in lines]\n",
    "liste_words = [line.split(\" \")[0] for line in lines]\n",
    "liste_occurences = [line.split(\" \")[1] for line in lines]\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"words\" : liste_words,\n",
    "                 \"occurences\" : liste_occurences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df003156",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a92cd44a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56708"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words from the occurence dataframe \n",
    "\n",
    "for i in range(len(stop_words)):\n",
    "    try :\n",
    "        df.drop([(df[df[\"words\"] == stop_words[i]]).index[0]], inplace=True)\n",
    "    except :\n",
    "        continue\n",
    "        \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_occu = df\n",
    "\n",
    "len(df_occu)\n",
    "\n",
    "df_occu.to_csv(\"cleaned_english_words_occurence.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fba626",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preprocessing Vocabulary English/French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cfd25cef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# vocabulary processing containing : english, french\n",
    "\n",
    "#vocabulary = pd.read_excel(\"Vocabulary.xlsx\")\n",
    "vocabulary=pd.read_csv('data.csv')\n",
    "#ici on tri en faisant du preprocessing + en enlevant les dupliqués exacts\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    special_punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for ele in text:\n",
    "        if ele in special_punc:\n",
    "            text = text.replace(ele, \"\")\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw = ' '.join([word for word in text_tokens if not word in stopwords.words()])\n",
    "    return tokens_without_sw\n",
    "\n",
    "def remove_empty(text):\n",
    "    return \" \".join(text.strip().split())\n",
    "\n",
    "def preprocessing_lower_punc_sw_stem(df, col_name):\n",
    "    \n",
    "    #Preprocessing (\" \",lower,punctuation,stop_words,stemming)\n",
    "    df[col_name]=df[col_name].apply(lambda x: remove_empty(x))\n",
    "    df[col_name]=df[col_name].apply(lambda x: x.lower())\n",
    "    \n",
    "    porter = PorterStemmer()\n",
    "    df[col_name + '_nopunct']=df[col_name].apply(lambda x: remove_punctuation(x))\n",
    "    df[col_name + '_noswords']=df[col_name + '_nopunct'].apply(lambda x: remove_stopwords(x))\n",
    "    df[col_name + '_stem']=df[col_name + '_noswords'].apply(lambda x: porter.stem(x))\n",
    "\n",
    "    #Duplicates\n",
    "    df=df.drop_duplicates(subset=[col_name])\n",
    "    df=df.drop_duplicates(subset=[col_name + '_stem'])\n",
    "    df=df.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "for col_name in [\"ENGLISH\", \"FRENCH\"]:\n",
    "    preprocessing_lower_punc_sw_stem(vocabulary, col_name)\n",
    "    \n",
    "# vocabulary.to_csv(\"clean_vocabulary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "89190ad6",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FRENCH</th>\n",
       "      <th>ENGLISH</th>\n",
       "      <th>THEME</th>\n",
       "      <th>IMPORTANT</th>\n",
       "      <th>ENGLISH_nopunct</th>\n",
       "      <th>ENGLISH_noswords</th>\n",
       "      <th>ENGLISH_stem</th>\n",
       "      <th>FRENCH_nopunct</th>\n",
       "      <th>FRENCH_noswords</th>\n",
       "      <th>FRENCH_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accepter</td>\n",
       "      <td>to accept</td>\n",
       "      <td>verbes a connaitre en</td>\n",
       "      <td>Non</td>\n",
       "      <td>to accept</td>\n",
       "      <td>accept</td>\n",
       "      <td>accept</td>\n",
       "      <td>accepter</td>\n",
       "      <td>accepter</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acheter</td>\n",
       "      <td>to buy</td>\n",
       "      <td>verbes a connaitre en</td>\n",
       "      <td>Non</td>\n",
       "      <td>to buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>acheter</td>\n",
       "      <td>acheter</td>\n",
       "      <td>achet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aider</td>\n",
       "      <td>to help</td>\n",
       "      <td>verbes a connaitre en</td>\n",
       "      <td>Non</td>\n",
       "      <td>to help</td>\n",
       "      <td>help</td>\n",
       "      <td>help</td>\n",
       "      <td>aider</td>\n",
       "      <td>aider</td>\n",
       "      <td>aider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aimer</td>\n",
       "      <td>to like, to love</td>\n",
       "      <td>verbes a connaitre en</td>\n",
       "      <td>Non</td>\n",
       "      <td>to like to love</td>\n",
       "      <td>like love</td>\n",
       "      <td>like lov</td>\n",
       "      <td>aimer</td>\n",
       "      <td>aimer</td>\n",
       "      <td>aimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ajouter</td>\n",
       "      <td>to add</td>\n",
       "      <td>verbes a connaitre en</td>\n",
       "      <td>Non</td>\n",
       "      <td>to add</td>\n",
       "      <td>add</td>\n",
       "      <td>add</td>\n",
       "      <td>ajouter</td>\n",
       "      <td>ajouter</td>\n",
       "      <td>ajout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14015</th>\n",
       "      <td>se rétablir de</td>\n",
       "      <td>to get over stg, to recover from</td>\n",
       "      <td>covid coronavirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to get over stg to recover from</td>\n",
       "      <td>get stg recover</td>\n",
       "      <td>get stg recov</td>\n",
       "      <td>se rétablir de</td>\n",
       "      <td>rétablir</td>\n",
       "      <td>rétablir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14016</th>\n",
       "      <td>soigner</td>\n",
       "      <td>to treat</td>\n",
       "      <td>covid coronavirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to treat</td>\n",
       "      <td>treat</td>\n",
       "      <td>treat</td>\n",
       "      <td>soigner</td>\n",
       "      <td>soigner</td>\n",
       "      <td>soigner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14017</th>\n",
       "      <td>tester les patients</td>\n",
       "      <td>to test patients</td>\n",
       "      <td>covid coronavirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to test patients</td>\n",
       "      <td>test patients</td>\n",
       "      <td>test pati</td>\n",
       "      <td>tester les patients</td>\n",
       "      <td>tester patients</td>\n",
       "      <td>tester pati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14018</th>\n",
       "      <td>tomber malade</td>\n",
       "      <td>to be taken ill</td>\n",
       "      <td>covid coronavirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to be taken ill</td>\n",
       "      <td>taken</td>\n",
       "      <td>taken</td>\n",
       "      <td>tomber malade</td>\n",
       "      <td>tomber malade</td>\n",
       "      <td>tomber malad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14019</th>\n",
       "      <td>transmettre une maladie</td>\n",
       "      <td>to transmit a disease</td>\n",
       "      <td>covid coronavirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to transmit a disease</td>\n",
       "      <td>transmit disease</td>\n",
       "      <td>transmit diseas</td>\n",
       "      <td>transmettre une maladie</td>\n",
       "      <td>transmettre maladie</td>\n",
       "      <td>transmettre maladi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14020 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        FRENCH                           ENGLISH  \\\n",
       "0                     accepter                         to accept   \n",
       "1                      acheter                            to buy   \n",
       "2                        aider                           to help   \n",
       "3                        aimer                  to like, to love   \n",
       "4                      ajouter                            to add   \n",
       "...                        ...                               ...   \n",
       "14015           se rétablir de  to get over stg, to recover from   \n",
       "14016                  soigner                          to treat   \n",
       "14017      tester les patients                  to test patients   \n",
       "14018            tomber malade                   to be taken ill   \n",
       "14019  transmettre une maladie             to transmit a disease   \n",
       "\n",
       "                       THEME IMPORTANT                  ENGLISH_nopunct  \\\n",
       "0      verbes a connaitre en       Non                        to accept   \n",
       "1      verbes a connaitre en       Non                           to buy   \n",
       "2      verbes a connaitre en       Non                          to help   \n",
       "3      verbes a connaitre en       Non                  to like to love   \n",
       "4      verbes a connaitre en       Non                           to add   \n",
       "...                      ...       ...                              ...   \n",
       "14015      covid coronavirus       NaN  to get over stg to recover from   \n",
       "14016      covid coronavirus       NaN                         to treat   \n",
       "14017      covid coronavirus       NaN                 to test patients   \n",
       "14018      covid coronavirus       NaN                  to be taken ill   \n",
       "14019      covid coronavirus       NaN            to transmit a disease   \n",
       "\n",
       "       ENGLISH_noswords     ENGLISH_stem           FRENCH_nopunct  \\\n",
       "0                accept           accept                 accepter   \n",
       "1                   buy              buy                  acheter   \n",
       "2                  help             help                    aider   \n",
       "3             like love         like lov                    aimer   \n",
       "4                   add              add                  ajouter   \n",
       "...                 ...              ...                      ...   \n",
       "14015   get stg recover    get stg recov           se rétablir de   \n",
       "14016             treat            treat                  soigner   \n",
       "14017     test patients        test pati      tester les patients   \n",
       "14018             taken            taken            tomber malade   \n",
       "14019  transmit disease  transmit diseas  transmettre une maladie   \n",
       "\n",
       "           FRENCH_noswords         FRENCH_stem  \n",
       "0                 accepter              accept  \n",
       "1                  acheter               achet  \n",
       "2                    aider               aider  \n",
       "3                    aimer               aimer  \n",
       "4                  ajouter               ajout  \n",
       "...                    ...                 ...  \n",
       "14015             rétablir            rétablir  \n",
       "14016              soigner             soigner  \n",
       "14017      tester patients         tester pati  \n",
       "14018        tomber malade        tomber malad  \n",
       "14019  transmettre maladie  transmettre maladi  \n",
       "\n",
       "[14020 rows x 10 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a04e407c",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOSEPH~1.PIC\\AppData\\Local\\Temp/ipykernel_34092/3349348133.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_voc2['Nearest_Neighbor']=df_voc2.iloc[id_nearest[:,1]]['ENGLISH'].tolist()\n",
      "C:\\Users\\JOSEPH~1.PIC\\AppData\\Local\\Temp/ipykernel_34092/3349348133.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_voc2['Proche_Voisin']=df_voc2.iloc[id_nearest[:,1]]['FRENCH'].tolist()\n",
      "C:\\Users\\JOSEPH~1.PIC\\AppData\\Local\\Temp/ipykernel_34092/3349348133.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_voc2['Distance_Nearest']=distance_nearest[:,1].tolist()\n",
      "C:\\Users\\JOSEPH~1.PIC\\AppData\\Local\\Temp/ipykernel_34092/3349348133.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_voc2['ID_Nearest_Neighbor']=id_nearest[:,1]\n"
     ]
    }
   ],
   "source": [
    "# Deduplication avec BallTree\n",
    "\n",
    "# from nltk.stem import LancasterStemmer\n",
    "from sklearn.neighbors import BallTree\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "#ici on essaye d'enlever les \"almost duplicate\" en vectorisant + utilisant BallTree sur les mots\n",
    "#autrement dit on crée les colonnes \"ID_Nearest_Neighbor\" et \"Distance_Nearest\" sur un échantillon de 2000 lignes\n",
    "sample_voc = vocabulary[0:2000]['ENGLISH_stem'].tolist()\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(sample_voc).todense()\n",
    "matrix = pd.DataFrame(matrix, columns=vectorizer.get_feature_names_out ())\n",
    "top_words = matrix.sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "tree = BallTree(matrix.values, leaf_size=2)\n",
    "\n",
    "distance_nearest, id_nearest = tree.query(\n",
    "    matrix.values,\n",
    "    k=3,)\n",
    "\n",
    "df_voc2=vocabulary[0:2000]\n",
    "df_voc2['Nearest_Neighbor']=df_voc2.iloc[id_nearest[:,1]]['ENGLISH'].tolist()\n",
    "df_voc2['Proche_Voisin']=df_voc2.iloc[id_nearest[:,1]]['FRENCH'].tolist()\n",
    "df_voc2['Distance_Nearest']=distance_nearest[:,1].tolist()\n",
    "df_voc2['ID_Nearest_Neighbor']=id_nearest[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f3526",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ici on delete les mots trop proche les uns des autres grâce au BallTree (dist<0.6)\n",
    "print(len(df_voc2[df_voc2.Distance_Nearest<0.6]))\n",
    "ids_todelete=df_voc2[df_voc2.Distance_Nearest<0.6].index.tolist()\n",
    "ids_close=df_voc2[df_voc2.Distance_Nearest<0.6]['ID_Nearest_Neighbor'].tolist()\n",
    "no_delete_ids=[]\n",
    "for count,id_todelete in enumerate(ids_todelete):\n",
    "    if id_todelete not in no_delete_ids:\n",
    "        df_voc2.drop([id_todelete],inplace=True)\n",
    "        no_delete_ids.append(ids_close[count])\n",
    "    else: \n",
    "        pass\n",
    "print(len(df_voc2[df_voc2.Distance_Nearest<0.6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9fc87",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fusion the two databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ce3bd04b",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FRENCH</th>\n",
       "      <th>ENGLISH</th>\n",
       "      <th>THEME</th>\n",
       "      <th>IMPORTANT</th>\n",
       "      <th>ENGLISH_nopunct</th>\n",
       "      <th>ENGLISH_noswords</th>\n",
       "      <th>ENGLISH_stem</th>\n",
       "      <th>FRENCH_nopunct</th>\n",
       "      <th>FRENCH_noswords</th>\n",
       "      <th>FRENCH_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accepter</td>\n",
       "      <td>to accept</td>\n",
       "      <td>verbes a connaitre en</td>\n",
       "      <td>Non</td>\n",
       "      <td>to accept</td>\n",
       "      <td>accept</td>\n",
       "      <td>accept</td>\n",
       "      <td>accepter</td>\n",
       "      <td>accepter</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acheter</td>\n",
       "      <td>to buy</td>\n",
       "      <td>verbes a connaitre en</td>\n",
       "      <td>Non</td>\n",
       "      <td>to buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "      <td>acheter</td>\n",
       "      <td>acheter</td>\n",
       "      <td>achet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aider</td>\n",
       "      <td>to help</td>\n",
       "      <td>verbes a connaitre en</td>\n",
       "      <td>Non</td>\n",
       "      <td>to help</td>\n",
       "      <td>help</td>\n",
       "      <td>help</td>\n",
       "      <td>aider</td>\n",
       "      <td>aider</td>\n",
       "      <td>aider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aimer</td>\n",
       "      <td>to like, to love</td>\n",
       "      <td>verbes a connaitre en</td>\n",
       "      <td>Non</td>\n",
       "      <td>to like to love</td>\n",
       "      <td>like love</td>\n",
       "      <td>like lov</td>\n",
       "      <td>aimer</td>\n",
       "      <td>aimer</td>\n",
       "      <td>aimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ajouter</td>\n",
       "      <td>to add</td>\n",
       "      <td>verbes a connaitre en</td>\n",
       "      <td>Non</td>\n",
       "      <td>to add</td>\n",
       "      <td>add</td>\n",
       "      <td>add</td>\n",
       "      <td>ajouter</td>\n",
       "      <td>ajouter</td>\n",
       "      <td>ajout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14015</th>\n",
       "      <td>se rétablir de</td>\n",
       "      <td>to get over stg, to recover from</td>\n",
       "      <td>covid coronavirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to get over stg to recover from</td>\n",
       "      <td>get stg recover</td>\n",
       "      <td>get stg recov</td>\n",
       "      <td>se rétablir de</td>\n",
       "      <td>rétablir</td>\n",
       "      <td>rétablir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14016</th>\n",
       "      <td>soigner</td>\n",
       "      <td>to treat</td>\n",
       "      <td>covid coronavirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to treat</td>\n",
       "      <td>treat</td>\n",
       "      <td>treat</td>\n",
       "      <td>soigner</td>\n",
       "      <td>soigner</td>\n",
       "      <td>soigner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14017</th>\n",
       "      <td>tester les patients</td>\n",
       "      <td>to test patients</td>\n",
       "      <td>covid coronavirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to test patients</td>\n",
       "      <td>test patients</td>\n",
       "      <td>test pati</td>\n",
       "      <td>tester les patients</td>\n",
       "      <td>tester patients</td>\n",
       "      <td>tester pati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14018</th>\n",
       "      <td>tomber malade</td>\n",
       "      <td>to be taken ill</td>\n",
       "      <td>covid coronavirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to be taken ill</td>\n",
       "      <td>taken</td>\n",
       "      <td>taken</td>\n",
       "      <td>tomber malade</td>\n",
       "      <td>tomber malade</td>\n",
       "      <td>tomber malad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14019</th>\n",
       "      <td>transmettre une maladie</td>\n",
       "      <td>to transmit a disease</td>\n",
       "      <td>covid coronavirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to transmit a disease</td>\n",
       "      <td>transmit disease</td>\n",
       "      <td>transmit diseas</td>\n",
       "      <td>transmettre une maladie</td>\n",
       "      <td>transmettre maladie</td>\n",
       "      <td>transmettre maladi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14020 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        FRENCH                           ENGLISH  \\\n",
       "0                     accepter                         to accept   \n",
       "1                      acheter                            to buy   \n",
       "2                        aider                           to help   \n",
       "3                        aimer                  to like, to love   \n",
       "4                      ajouter                            to add   \n",
       "...                        ...                               ...   \n",
       "14015           se rétablir de  to get over stg, to recover from   \n",
       "14016                  soigner                          to treat   \n",
       "14017      tester les patients                  to test patients   \n",
       "14018            tomber malade                   to be taken ill   \n",
       "14019  transmettre une maladie             to transmit a disease   \n",
       "\n",
       "                       THEME IMPORTANT                  ENGLISH_nopunct  \\\n",
       "0      verbes a connaitre en       Non                        to accept   \n",
       "1      verbes a connaitre en       Non                           to buy   \n",
       "2      verbes a connaitre en       Non                          to help   \n",
       "3      verbes a connaitre en       Non                  to like to love   \n",
       "4      verbes a connaitre en       Non                           to add   \n",
       "...                      ...       ...                              ...   \n",
       "14015      covid coronavirus       NaN  to get over stg to recover from   \n",
       "14016      covid coronavirus       NaN                         to treat   \n",
       "14017      covid coronavirus       NaN                 to test patients   \n",
       "14018      covid coronavirus       NaN                  to be taken ill   \n",
       "14019      covid coronavirus       NaN            to transmit a disease   \n",
       "\n",
       "       ENGLISH_noswords     ENGLISH_stem           FRENCH_nopunct  \\\n",
       "0                accept           accept                 accepter   \n",
       "1                   buy              buy                  acheter   \n",
       "2                  help             help                    aider   \n",
       "3             like love         like lov                    aimer   \n",
       "4                   add              add                  ajouter   \n",
       "...                 ...              ...                      ...   \n",
       "14015   get stg recover    get stg recov           se rétablir de   \n",
       "14016             treat            treat                  soigner   \n",
       "14017     test patients        test pati      tester les patients   \n",
       "14018             taken            taken            tomber malade   \n",
       "14019  transmit disease  transmit diseas  transmettre une maladie   \n",
       "\n",
       "           FRENCH_noswords         FRENCH_stem  \n",
       "0                 accepter              accept  \n",
       "1                  acheter               achet  \n",
       "2                    aider               aider  \n",
       "3                    aimer               aimer  \n",
       "4                  ajouter               ajout  \n",
       "...                    ...                 ...  \n",
       "14015             rétablir            rétablir  \n",
       "14016              soigner             soigner  \n",
       "14017      tester patients         tester pati  \n",
       "14018        tomber malade        tomber malad  \n",
       "14019  transmettre maladie  transmettre maladi  \n",
       "\n",
       "[14020 rows x 10 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "39cd881c",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also</td>\n",
       "      <td>5450043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first</td>\n",
       "      <td>4840311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>4151416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new</td>\n",
       "      <td>4039430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>two</td>\n",
       "      <td>3415323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56703</th>\n",
       "      <td>outstep</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56704</th>\n",
       "      <td>rescans</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56705</th>\n",
       "      <td>unbelieved</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56706</th>\n",
       "      <td>unclasping</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56707</th>\n",
       "      <td>gallivanted</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56708 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             words  occurences\n",
       "0             also     5450043\n",
       "1            first     4840311\n",
       "2              one     4151416\n",
       "3              new     4039430\n",
       "4              two     3415323\n",
       "...            ...         ...\n",
       "56703      outstep           3\n",
       "56704      rescans           3\n",
       "56705   unbelieved           3\n",
       "56706   unclasping           3\n",
       "56707  gallivanted           3\n",
       "\n",
       "[56708 rows x 2 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_english_words_occurence = pd.read_csv(\"cleaned_english_words_occurence.csv\", index_col=0)\n",
    "cleaned_english_words_occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0829b3f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_voc = vocabulary[0:2000]['ENGLISH_stem'].tolist()\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(sample_voc).todense()\n",
    "matrix = pd.DataFrame(matrix, columns=vectorizer.get_feature_names_out ())\n",
    "top_words = matrix.sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "tree = BallTree(matrix.values, leaf_size=2)\n",
    "\n",
    "distance_nearest, id_nearest = tree.query(\n",
    "    matrix.values,\n",
    "    k=3,)\n",
    "\n",
    "df_voc2=vocabulary[0:2000]\n",
    "df_voc2['Nearest_Neighbor']=df_voc2.iloc[id_nearest[:,1]]['ENGLISH'].tolist()\n",
    "df_voc2['Proche_Voisin']=df_voc2.iloc[id_nearest[:,1]]['FRENCH'].tolist()\n",
    "df_voc2['Distance_Nearest']=distance_nearest[:,1].tolist()\n",
    "df_voc2['ID_Nearest_Neighbor']=id_nearest[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a3606cd1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocabulary.to_csv(\"clean_vocabulary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f3010",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f58a051e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also</td>\n",
       "      <td>5450043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first</td>\n",
       "      <td>4840311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>4151416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new</td>\n",
       "      <td>4039430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>two</td>\n",
       "      <td>3415323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56703</th>\n",
       "      <td>outstep</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56704</th>\n",
       "      <td>rescans</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56705</th>\n",
       "      <td>unbelieved</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56706</th>\n",
       "      <td>unclasping</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56707</th>\n",
       "      <td>gallivanted</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56708 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             words  occurences\n",
       "0             also     5450043\n",
       "1            first     4840311\n",
       "2              one     4151416\n",
       "3              new     4039430\n",
       "4              two     3415323\n",
       "...            ...         ...\n",
       "56703      outstep           3\n",
       "56704      rescans           3\n",
       "56705   unbelieved           3\n",
       "56706   unclasping           3\n",
       "56707  gallivanted           3\n",
       "\n",
       "[56708 rows x 2 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abafc44c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cleaned_english_words_occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebca451d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "french_column = 'french'\n",
    "english_column = 'english'\n",
    "stem_colmun = 'stem'\n",
    "\n",
    "df_french_english = pd.DataFrame(columns=[french_column, english_column, stem_colmun])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7192c0e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_french_english.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73a9c0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7251c4ef",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>french</th>\n",
       "      <th>english</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [french, english, stem]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_french_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1f8db",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_excel(\"english_frequency_list.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db14f41",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
