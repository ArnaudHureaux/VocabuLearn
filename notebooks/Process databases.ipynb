{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "19277c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fuzzywuzzy\n",
    "# pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c65ec038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import os as os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d7ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=pd.read_csv('inputs/Vocabulearn_all.csv')\n",
    "\n",
    "#Fonction de filtre globale\n",
    "def remove_punctuation(text):\n",
    "    special_punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for ele in text:\n",
    "        if ele in special_punc:\n",
    "            text = text.replace(ele, \" \")\n",
    "    return text\n",
    "langues=list(set(list(df_raw.columns))-set(['ID','ENGLISH_stem','OCCURENCES','INTERVAL']))\n",
    "\n",
    "def process_global(df):\n",
    "    df['INTERVAL']=pd.qcut(df['OCCURENCES'],100,duplicates='drop',labels=False)\n",
    "    df['INTERVAL']=100-df['INTERVAL']\n",
    "    for column in langues:\n",
    "        df[column]=df[column].apply(remove_punctuation)\n",
    "    return df\n",
    "df_global=process_global(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eec8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split en plusieurs dataset\n",
    "dicte_langue={}\n",
    "for langue in langues:\n",
    "    dicte_langue[langue]=df_global[['ID',langue]]\n",
    "df_interval=df_global[['ID','INTERVAL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9817de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "langues_bizarre=['CHINESE','KOREAN','JAPAN','RUSSIAN','ARABE','HINDI']\n",
    "langues_normale=list(set(langues)-set(langues_bizarre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6572c6ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-2e837b100cac>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_len']=df[langue].apply(len)\n",
      "<ipython-input-9-2e837b100cac>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_len']=df[langue].apply(len)\n",
      "<ipython-input-9-2e837b100cac>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_len']=df[langue].apply(len)\n",
      "<ipython-input-9-2e837b100cac>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_len']=df[langue].apply(len)\n",
      "<ipython-input-9-2e837b100cac>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_len']=df[langue].apply(len)\n",
      "<ipython-input-9-2e837b100cac>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_len']=df[langue].apply(len)\n",
      "<ipython-input-9-2e837b100cac>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_len']=df[langue].apply(len)\n",
      "<ipython-input-9-2e837b100cac>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_len']=df[langue].apply(len)\n"
     ]
    }
   ],
   "source": [
    "#Filtre de chaque dataset selon son type\n",
    "def filtre_langue_normale(df,langue):\n",
    "    df['_len']=df[langue].apply(len)\n",
    "    df=df[(df['_len']>3)&(df['_len']<20)]\n",
    "    df=df.drop(columns=['_len'])\n",
    "    return df\n",
    "for langue in langues_normale:\n",
    "    dicte_langue[langue]=filtre_langue_normale(dicte_langue[langue],langue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40280cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-fd398ee1370f>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_contain_latin']=df[langue].apply(filter_latin)\n"
     ]
    }
   ],
   "source": [
    "langues_bizarre=['CHINESE','KOREAN','JAPAN','RUSSIAN','ARABE','CHINESE']\n",
    "def filtre_langue_bizarre(df,langue):\n",
    "    def filter_latin(text):\n",
    "        text=text.lower()\n",
    "        alphabet=\"abcdefghijklmnopqrstvwxyzéèêìîï\"\n",
    "        for letter in alphabet:\n",
    "            if letter in text:\n",
    "                return False\n",
    "        return True\n",
    "    df['_contain_latin']=df[langue].apply(filter_latin)\n",
    "    df=df[df['_contain_latin']]\n",
    "    df=df.drop(columns=['_contain_latin'])\n",
    "    return df\n",
    "for langue in langues_bizarre:\n",
    "    dicte_langue[langue]=filtre_langue_bizarre(dicte_langue[langue],langue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c92c9c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtre post-selection\n",
    "def merge_and_filter(speak,learn):\n",
    "    speak_df=dicte_langue[speak]\n",
    "    learn_df=dicte_langue[learn]\n",
    "    df=speak_df.merge(learn_df, how='inner', on='ID')\n",
    "    df=df.merge(df_interval, how='inner', on='ID')\n",
    "    df['_is_egal']=df[speak]==df[learn]\n",
    "    df=df[~df['_is_egal']]\n",
    "    df['_fuzzy_ratio'] = df.apply(lambda x: fuzz.ratio(x[speak], x[learn]), axis=1)\n",
    "    df=df[df['_fuzzy_ratio']<70]\n",
    "    df=df.drop(columns=['_is_egal','_fuzzy_ratio'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6ef62151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PORTUGAIS ENGLISH 5376\n",
      "PORTUGAIS CHINESE 10923\n",
      "PORTUGAIS KOREAN 11792\n",
      "PORTUGAIS JAPAN 10603\n",
      "PORTUGAIS FRENCH 6601\n",
      "PORTUGAIS HINDI 12321\n",
      "PORTUGAIS DEUTSCH 7689\n",
      "PORTUGAIS SPAIN 4375\n",
      "PORTUGAIS POLONAIS 7458\n",
      "PORTUGAIS TURC 7717\n",
      "PORTUGAIS RUSSIAN 11843\n",
      "PORTUGAIS ARABE 11495\n",
      "PORTUGAIS DANOIS 6758\n",
      "ENGLISH PORTUGAIS 5377\n",
      "ENGLISH CHINESE 11100\n",
      "ENGLISH KOREAN 11814\n",
      "ENGLISH JAPAN 10764\n",
      "ENGLISH FRENCH 5333\n",
      "ENGLISH HINDI 12173\n",
      "ENGLISH DEUTSCH 6365\n",
      "ENGLISH SPAIN 5741\n",
      "ENGLISH POLONAIS 7152\n",
      "ENGLISH TURC 7012\n",
      "ENGLISH RUSSIAN 11828\n",
      "ENGLISH ARABE 11452\n",
      "ENGLISH DANOIS 4852\n",
      "CHINESE PORTUGAIS 10923\n",
      "CHINESE ENGLISH 11100\n",
      "CHINESE KOREAN 11523\n",
      "CHINESE JAPAN 9826\n",
      "CHINESE FRENCH 10664\n",
      "CHINESE HINDI 11894\n",
      "CHINESE DEUTSCH 10750\n",
      "CHINESE SPAIN 10641\n",
      "CHINESE POLONAIS 10647\n",
      "CHINESE TURC 10700\n",
      "CHINESE RUSSIAN 11524\n",
      "CHINESE ARABE 11242\n",
      "CHINESE DANOIS 10942\n",
      "KOREAN PORTUGAIS 11792\n",
      "KOREAN ENGLISH 11814\n",
      "KOREAN CHINESE 11523\n",
      "KOREAN JAPAN 11002\n",
      "KOREAN FRENCH 11423\n",
      "KOREAN HINDI 12870\n",
      "KOREAN DEUTSCH 11574\n",
      "KOREAN SPAIN 11412\n",
      "KOREAN POLONAIS 11484\n",
      "KOREAN TURC 11421\n",
      "KOREAN RUSSIAN 12378\n",
      "KOREAN ARABE 12067\n",
      "KOREAN DANOIS 11835\n",
      "JAPAN PORTUGAIS 10603\n",
      "JAPAN ENGLISH 10764\n",
      "JAPAN CHINESE 9826\n",
      "JAPAN KOREAN 11002\n",
      "JAPAN FRENCH 10346\n",
      "JAPAN HINDI 11498\n",
      "JAPAN DEUTSCH 10440\n",
      "JAPAN SPAIN 10344\n",
      "JAPAN POLONAIS 10329\n",
      "JAPAN TURC 10389\n",
      "JAPAN RUSSIAN 11027\n",
      "JAPAN ARABE 10758\n",
      "JAPAN DANOIS 10603\n",
      "FRENCH PORTUGAIS 6592\n",
      "FRENCH ENGLISH 5323\n",
      "FRENCH CHINESE 10664\n",
      "FRENCH KOREAN 11423\n",
      "FRENCH JAPAN 10346\n",
      "FRENCH HINDI 11865\n",
      "FRENCH DEUTSCH 7387\n",
      "FRENCH SPAIN 6179\n",
      "FRENCH POLONAIS 7904\n",
      "FRENCH TURC 7645\n",
      "FRENCH RUSSIAN 11476\n",
      "FRENCH ARABE 11127\n",
      "FRENCH DANOIS 7132\n",
      "HINDI PORTUGAIS 12321\n",
      "HINDI ENGLISH 12173\n",
      "HINDI CHINESE 11894\n",
      "HINDI KOREAN 12870\n",
      "HINDI JAPAN 11498\n",
      "HINDI FRENCH 11865\n",
      "HINDI DEUTSCH 12053\n",
      "HINDI SPAIN 11868\n",
      "HINDI POLONAIS 12016\n",
      "HINDI TURC 11851\n",
      "HINDI RUSSIAN 13043\n",
      "HINDI ARABE 12643\n",
      "HINDI DANOIS 12349\n",
      "DEUTSCH PORTUGAIS 7691\n",
      "DEUTSCH ENGLISH 6364\n",
      "DEUTSCH CHINESE 10750\n",
      "DEUTSCH KOREAN 11574\n",
      "DEUTSCH JAPAN 10440\n",
      "DEUTSCH FRENCH 7393\n",
      "DEUTSCH HINDI 12053\n",
      "DEUTSCH SPAIN 7981\n",
      "DEUTSCH POLONAIS 7758\n",
      "DEUTSCH TURC 7862\n",
      "DEUTSCH RUSSIAN 11613\n",
      "DEUTSCH ARABE 11288\n",
      "DEUTSCH DANOIS 6406\n",
      "SPAIN PORTUGAIS 4371\n",
      "SPAIN ENGLISH 5739\n",
      "SPAIN CHINESE 10641\n",
      "SPAIN KOREAN 11412\n",
      "SPAIN JAPAN 10344\n",
      "SPAIN FRENCH 6178\n",
      "SPAIN HINDI 11868\n",
      "SPAIN DEUTSCH 7980\n",
      "SPAIN POLONAIS 7729\n",
      "SPAIN TURC 7736\n",
      "SPAIN RUSSIAN 11473\n",
      "SPAIN ARABE 11130\n",
      "SPAIN DANOIS 7608\n",
      "POLONAIS PORTUGAIS 7458\n",
      "POLONAIS ENGLISH 7153\n",
      "POLONAIS CHINESE 10647\n",
      "POLONAIS KOREAN 11484\n",
      "POLONAIS JAPAN 10329\n",
      "POLONAIS FRENCH 7906\n",
      "POLONAIS HINDI 12016\n",
      "POLONAIS DEUTSCH 7757\n",
      "POLONAIS SPAIN 7729\n",
      "POLONAIS TURC 7739\n",
      "POLONAIS RUSSIAN 11537\n",
      "POLONAIS ARABE 11217\n",
      "POLONAIS DANOIS 7210\n",
      "TURC PORTUGAIS 7720\n",
      "TURC ENGLISH 7011\n",
      "TURC CHINESE 10700\n",
      "TURC KOREAN 11421\n",
      "TURC JAPAN 10389\n",
      "TURC FRENCH 7646\n",
      "TURC HINDI 11851\n",
      "TURC DEUTSCH 7862\n",
      "TURC SPAIN 7736\n",
      "TURC POLONAIS 7742\n",
      "TURC RUSSIAN 11451\n",
      "TURC ARABE 11086\n",
      "TURC DANOIS 7429\n",
      "RUSSIAN PORTUGAIS 11843\n",
      "RUSSIAN ENGLISH 11828\n",
      "RUSSIAN CHINESE 11524\n",
      "RUSSIAN KOREAN 12378\n",
      "RUSSIAN JAPAN 11027\n",
      "RUSSIAN FRENCH 11476\n",
      "RUSSIAN HINDI 13043\n",
      "RUSSIAN DEUTSCH 11613\n",
      "RUSSIAN SPAIN 11473\n",
      "RUSSIAN POLONAIS 11537\n",
      "RUSSIAN TURC 11451\n",
      "RUSSIAN ARABE 12153\n",
      "RUSSIAN DANOIS 11883\n",
      "ARABE PORTUGAIS 11495\n",
      "ARABE ENGLISH 11452\n",
      "ARABE CHINESE 11242\n",
      "ARABE KOREAN 12067\n",
      "ARABE JAPAN 10758\n",
      "ARABE FRENCH 11127\n",
      "ARABE HINDI 12643\n",
      "ARABE DEUTSCH 11288\n",
      "ARABE SPAIN 11130\n",
      "ARABE POLONAIS 11217\n",
      "ARABE TURC 11086\n",
      "ARABE RUSSIAN 12153\n",
      "ARABE DANOIS 11536\n",
      "DANOIS PORTUGAIS 6760\n",
      "DANOIS ENGLISH 4853\n",
      "DANOIS CHINESE 10942\n",
      "DANOIS KOREAN 11835\n",
      "DANOIS JAPAN 10603\n",
      "DANOIS FRENCH 7144\n",
      "DANOIS HINDI 12349\n",
      "DANOIS DEUTSCH 6406\n",
      "DANOIS SPAIN 7609\n",
      "DANOIS POLONAIS 7210\n",
      "DANOIS TURC 7429\n",
      "DANOIS RUSSIAN 11883\n",
      "DANOIS ARABE 11536\n"
     ]
    }
   ],
   "source": [
    "for langue_speak in langues:\n",
    "    try:\n",
    "        os.mkdir(path+'\\\\output\\\\dataset\\\\'+langue_speak)\n",
    "    except:\n",
    "        print('Error on',langue_speak)\n",
    "    langues2=[langue for langue in langues if langue!=langue_speak]\n",
    "    for langue_learn in langues2:\n",
    "        df=merge_and_filter(langue_speak,langue_learn)\n",
    "        df=df.sample(frac=1)\n",
    "        df.to_csv(path+'\\\\output\\\\dataset\\\\'+langue_speak+'\\\\'+langue_speak+'_'+langue_learn+'.csv',header=True,index=False)\n",
    "        print(langue_speak,langue_learn,len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
