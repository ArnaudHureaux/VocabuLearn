{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b795e5f2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.26.2)\n",
      "Collecting numpy\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/99/2b/f7114983d84303019385d93d24d729aedba67be7e083286f114188943cf3/numpy-1.26.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.26.3-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.2 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.2 kB 222.6 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/61.2 kB 220.2 kB/s eta 0:00:01\n",
      "     ------------------------------- ------ 51.2/61.2 kB 292.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.2/61.2 kB 298.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.11.1)\n",
      "Collecting scipy\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/43/d0/f3cd75b62e1b90f48dbf091261b2fc7ceec14a700e308c50f6a69c83d337/scipy-1.11.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.4/60.4 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/4e/ba/ce9bd1cd4953336a0e213b29cb80bb11816f2a93de8c99f88ef0b446ad0c/scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Downloading numpy-1.26.3-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.8 MB 9.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.3/15.8 MB 16.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.6/15.8 MB 36.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.2/15.8 MB 47.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.3/15.8 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 54.7 MB/s eta 0:00:00\n",
      "Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl (44.1 MB)\n",
      "   ---------------------------------------- 0.0/44.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.9/44.1 MB 92.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 6.9/44.1 MB 88.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 10.2/44.1 MB 81.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 14.2/44.1 MB 81.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 16.3/44.1 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 19.6/44.1 MB 65.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 22.7/44.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 25.7/44.1 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 28.7/44.1 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 30.8/44.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 33.8/44.1 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.2/44.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.3/44.1 MB 65.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.3/44.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/44.1 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.1/44.1 MB 28.5 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 4.9/9.2 MB 78.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 97.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 65.2 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, scipy, scikit-learn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.2\n",
      "    Uninstalling numpy-1.26.2:\n",
      "      Successfully uninstalled numpy-1.26.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Accès refusé: 'C:\\\\Users\\\\DELL\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy.libs\\\\libopenblas64__v0.3.23-293-gc2f4bdbb-gcc_10_3_0-2bde3a66a51006b2b53eb373ff767a3f.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6d3096a7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Collecting threadpoolctl\n",
      "  Obtaining dependency information for threadpoolctl from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "Successfully installed threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade threadpoolctl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9329717",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall numpy\n",
    "!pip install numpy==1.21.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3b7be454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa63270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    try:\n",
    "        ps = PorterStemmer()\n",
    "        return ps.stem(text)\n",
    "    except:\n",
    "        print('error')\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b19118",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_wiki=\"inputs/WikiWords_FirstMillion_Refined_V6.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa72c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_words=\"inputs/Google_sheet_2024.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ab45a",
   "metadata": {},
   "source": [
    "#### Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8272372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki=pd.read_csv(path_wiki)\n",
    "wiki.columns=['ENGLISH','OCCURENCES']\n",
    "wiki=wiki[wiki['ENGLISH'].notna()]\n",
    "wiki=wiki.drop_duplicates(subset=['ENGLISH'])\n",
    "wiki['ENGLISH_stem']=wiki['ENGLISH'].apply(stem)\n",
    "agg_dicte={'ENGLISH': 'first', 'OCCURENCES': 'sum'}\n",
    "grouped_wiki = wiki.groupby('ENGLISH_stem').agg(agg_dicte).reset_index()\n",
    "grouped_wiki=grouped_wiki[['ENGLISH_stem','OCCURENCES']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b920884f",
   "metadata": {},
   "source": [
    "#### Google Sheet's words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "561abc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=pd.read_csv(path_words)\n",
    "words['ENGLISH_stem']=words['ENGLISH'].apply(stem)\n",
    "words=words.drop_duplicates(subset=['ENGLISH'])\n",
    "words=words.drop(columns='OCCURENCES')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a9d5d",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20e5f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=words.merge(grouped_wiki,how='left',left_on=['ENGLISH_stem'],right_on=['ENGLISH_stem'])\n",
    "words=words[words['OCCURENCES'].notna()]\n",
    "words=words.sort_values(by='OCCURENCES', ascending=False)\n",
    "words['ID']=words.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8830737",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2a0768fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "langues=list(set(list(words.columns))-set(['ID','ENGLISH_stem','OCCURENCES']))\n",
    "langues_bizarre=['CHINESE','KOREAN','JAPAN','RUSSIAN','ARABE','CHINESE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ec5c05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words['INTERVAL']=pd.qcut(words['OCCURENCES'],100,duplicates='drop',labels=False)\n",
    "words['INTERVAL']=100-words['INTERVAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1f5ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_latin(text):\n",
    "    text_lower=text.lower()\n",
    "    alphabet=\"abcdefghijklmnopqrstvwxyzéèêìîï\"\n",
    "    for letter in alphabet:\n",
    "        if letter in text_lower:\n",
    "            return ''\n",
    "    return text\n",
    "for langue in langues_bizarre:\n",
    "    mask=words[langue].notna()\n",
    "    words[langue]=words[mask][langue].apply(filter_latin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b51be56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    special_punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for ele in text:\n",
    "        if ele in special_punc:\n",
    "            text = text.replace(ele, \" \")\n",
    "    return text\n",
    "for langue in langues:\n",
    "    mask=words[langue].notna()\n",
    "    words[langue]=words[mask][langue].apply(remove_punctuation)\n",
    "    words[langue] = words[mask][langue].apply(lambda x: '' if x.strip() == '' else x)\n",
    "    words[langue]=words[langue].fillna('')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8b81dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f77fb107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:29<00:00,  6.40s/it]\n"
     ]
    }
   ],
   "source": [
    "for langue_speak in tqdm(langues):\n",
    "    try:\n",
    "        os.mkdir('output/dataset/'+langue_speak)\n",
    "    except Exception as E:\n",
    "        pass\n",
    "    langues_learns=[langue for langue in langues if langue!=langue_speak]\n",
    "    for langue_learn in langues_learns:\n",
    "\n",
    "        df=words[['ID',langue_speak,langue_learn,'OCCURENCES']]\n",
    "        \n",
    "        df[langue_learn]=df[langue_learn].apply(str)\n",
    "        df[langue_speak]=df[langue_speak].apply(str)\n",
    "        \n",
    "        df=df[(df[langue_learn].notna())&(df[langue_speak].notna())]\n",
    "        \n",
    "        df[langue_learn]=df[langue_learn].apply(lambda x: x.lower())\n",
    "        df[langue_speak]=df[langue_speak].apply(lambda x: x.lower())\n",
    "        \n",
    "        df=df.drop_duplicates(subset=[langue_learn])\n",
    "        df=df.drop_duplicates(subset=[langue_speak])\n",
    "        \n",
    "        df[langue_speak]=df[langue_speak].apply(lambda x: x.replace(\"'\",' ').replace('\"',' ').replace(',',' ').replace('{',' ').replace('}',' '))\n",
    "        df[langue_learn]=df[langue_learn].apply(lambda x: x.replace(\"'\",' ').replace('\"',' ').replace(',',' ').replace('{',' ').replace('}',' '))\n",
    "        \n",
    "        df['_is_egal']=df[langue_speak]==df[langue_learn]\n",
    "        df=df[~df['_is_egal']]\n",
    "        \n",
    "        df['_fuzzy_ratio'] = df.apply(lambda x: fuzz.ratio(x[langue_speak], x[langue_learn]), axis=1)\n",
    "        df=df[df['_fuzzy_ratio']<70]\n",
    "        df=df.drop(columns=['_is_egal','_fuzzy_ratio'])\n",
    "        df['INTERVAL']=pd.qcut(df['OCCURENCES'],100,duplicates='drop',labels=False)\n",
    "        df['INTERVAL']=100-df['INTERVAL']\n",
    "        df['INTERVAL']=round((df['INTERVAL']+4)/104*100).apply(lambda x: int(x))\n",
    "        df=df.drop(columns=['OCCURENCES'])\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        df=df[(df[langue_learn].notna())&(df[langue_speak].notna())&(df[langue_learn]!='nan')&(df[langue_speak]!='nan')&(df[langue_learn]!='null')&(df[langue_speak]!='null')]\n",
    "        #print(langue_speak+'_'+langue_learn+'.csv',len(df),df[langue_speak].isna().mean(),df[langue_learn].isna().mean())\n",
    "        df.to_csv('output/dataset/'+langue_speak+'/'+langue_speak+'_'+langue_learn+'.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f22460a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CHINESE</th>\n",
       "      <th>RUSSIAN</th>\n",
       "      <th>INTERVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13793</th>\n",
       "      <td>13793</td>\n",
       "      <td>到</td>\n",
       "      <td>к</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13791</th>\n",
       "      <td>13791</td>\n",
       "      <td>这</td>\n",
       "      <td>а</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>13837</td>\n",
       "      <td>你</td>\n",
       "      <td>ты</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13794</th>\n",
       "      <td>13794</td>\n",
       "      <td>和</td>\n",
       "      <td>и</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>13839</td>\n",
       "      <td>A</td>\n",
       "      <td>А</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>多孔</td>\n",
       "      <td>пористый</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>欧洲环保局</td>\n",
       "      <td>EPA</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>卡仕达酱</td>\n",
       "      <td>заварной крем</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>188</td>\n",
       "      <td>ROX.</td>\n",
       "      <td>рокс</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14255</th>\n",
       "      <td>14255</td>\n",
       "      <td>很重要</td>\n",
       "      <td>Связь</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10453 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID CHINESE        RUSSIAN  INTERVAL\n",
       "13793  13793       到              к         5\n",
       "13791  13791       这              а         5\n",
       "13837  13837       你             ты         5\n",
       "13794  13794       和              и         5\n",
       "13839  13839       A              А         5\n",
       "...      ...     ...            ...       ...\n",
       "137      137      多孔       пористый       100\n",
       "136      136   欧洲环保局            EPA       100\n",
       "135      135    卡仕达酱  заварной крем       100\n",
       "188      188    ROX.           рокс       100\n",
       "14255  14255     很重要          Связь       100\n",
       "\n",
       "[10453 rows x 4 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
